{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:26:04.446575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Experimental classifier that uses a CNN architecture and softmax activation in the last layer\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.metrics as skm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "\n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "test_dataset = np.load(data_path + 'test_Euclid_res_20000_TestStars_id_002GT_100_bins.npy', allow_pickle=True)[()]\n",
    "train_dataset = np.load(data_path + 'train_Euclid_res_52000_TrainStars_id_002GT_100_bins.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_success_rate(confusion_matrix):\n",
    "    \"\"\" Metric that contemplates success as the true spectral class with a tolerance of one adjacent class\n",
    "    \"\"\"\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate\n",
    "\n",
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\" Callback to display training information only at the end of the training of one network\n",
    "    \"\"\"\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "        final_acc = self.model.history.history['categorical_accuracy'][-1]\n",
    "        final_val_acc = self.model.history.history['val_categorical_accuracy'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "        print(\"Final accuracy:\", final_acc, \"Final validation accuracy:\", final_val_acc)\n",
    "\n",
    "completion_callback = TrainingCompletionCallback()\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed = 25)\n",
    "\n",
    "star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "class CNN_model:\n",
    "    \"\"\"Wrapper class to train the network with a PCA dataset and a given architecture.\"\"\"\n",
    "    def __init__(self, train_dataset, test_dataset, architecture):\n",
    "        \"\"\"Receives the name of the dataset and the already created network and loads the needed variables.\"\"\"\n",
    "        train_stars = np.expand_dims(train_dataset['noisy_stars'], axis = 3)\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(train_stars,\n",
    "                                                                               train_dataset['SED_ids'],test_size = 20000, shuffle = False) # Reserve 20,000 stars for validation\n",
    "        self.x_test = np.expand_dims(test_dataset['noisy_stars'], axis = 3)\n",
    "        self.y_test = test_dataset['SED_ids']\n",
    "        self.y_train_cat = tf.keras.utils.to_categorical(self.y_train,num_classes = 13)\n",
    "        self.y_val_cat = tf.keras.utils.to_categorical(self.y_val,num_classes = 13)\n",
    "        self.y_test_cat = tf.keras.utils.to_categorical(self.y_test,num_classes = 13)\n",
    "        self.learning = []\n",
    "        self.model = architecture\n",
    "        \n",
    "    \n",
    "    def train_model(self, learning_rate, training_epochs, patience_epochs):\n",
    "\n",
    "        self.model.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "            metrics = 'categorical_accuracy'\n",
    "        )\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "\n",
    "        learn = self.model.fit(self.x_train, self.y_train_cat, epochs= training_epochs, verbose = 0,\n",
    "                                        callbacks = [completion_callback,early_stopping], validation_data=(self.x_val,self.y_val_cat), shuffle=True) \n",
    "\n",
    "        self.learning.append(learn)\n",
    "\n",
    "    def predict_test(self, verbose = True):\n",
    "        \"\"\"Makes predictions on the test data.\"\"\"\n",
    "        y_test_pred = self.model.predict(self.x_test)\n",
    "        class_predictions = np.argmax(y_test_pred, axis = 1)\n",
    "\n",
    "        self.f1_test = skm.f1_score(self.y_test, class_predictions, average = None)\n",
    "        self.f1_mean_test = np.mean(self.f1_test[:13])\n",
    "        self.confusion_matrix_test = skm.confusion_matrix(self.y_test, class_predictions)\n",
    "        self.success_rate_test = calculate_success_rate(self.confusion_matrix_test)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the test set\")\n",
    "            print('Average F1 score:', self.f1_mean_test)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_test)\n",
    "            print('\\nSuccess rate:', self.success_rate_test)\n",
    "\n",
    "\n",
    "    def predict_val(self, verbose = True):\n",
    "        \"\"\"Makes predictions on the validation data.\"\"\"\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        class_predictions = np.argmax(y_val_pred, axis = 1)\n",
    "\n",
    "        self.f1_val = skm.f1_score(self.y_val, class_predictions, average = None)\n",
    "        self.f1_mean_val = np.mean(self.f1_val[:13])\n",
    "        self.confusion_matrix_val = skm.confusion_matrix(self.y_val, class_predictions)\n",
    "        self.success_rate_val = calculate_success_rate(self.confusion_matrix_val)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the validation set\")\n",
    "            print('Average F1 score:', self.f1_mean_val)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_val)\n",
    "            print('\\nSuccess rate:', self.success_rate_val)\n",
    "\n",
    "    def save_model(self, N_model = 1):\n",
    "\n",
    "        self.model.save(f\"saved_models/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "\n",
    "    def load_model(self, N_model = 1):\n",
    "        self.model = tf.keras.models.load_model(f\"saved_models/{self.configuration['config_name']}/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "        \n",
    "\n",
    "    def plot_training_evolution(self):\n",
    "        \"\"\"Plot the loss function and accuracy evolution.\"\"\"\n",
    "\n",
    "        loss_evolution = self.learning[-1].history[\"loss\"]\n",
    "        val_loss_evolution = self.learning[-1].history[\"val_loss\"]\n",
    "        acc_evolution = self.learning[-1].history['categorical_accuracy']\n",
    "        val_acc_evolution = self.learning[-1].history['val_categorical_accuracy']\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(loss_evolution,label = \"Train set\")\n",
    "        plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss function value\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss function evolution\")\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(acc_evolution)\n",
    "        plt.plot(acc_evolution,label = \"Train set\")\n",
    "        plt.plot(val_acc_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Categorical accuracy evolution\")\n",
    "\n",
    "        print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n",
    "        print(\"Training accuracy:\", acc_evolution[-1], \", Validation accuracy:\", val_acc_evolution[-1])\n",
    "\n",
    "    def plot_cf_matrix(self):\n",
    "        plt.figure(figsize= (12,10))\n",
    "        heatmap = plt.imshow(self.confusion_matrix_test[:13,:], cmap='Blues')\n",
    "        plt.xticks(np.arange(13), star_class_labels)\n",
    "        plt.yticks(np.arange(13), star_class_labels)\n",
    "        plt.colorbar(heatmap)\n",
    "        plt.xlabel(\"Estimated spectral type\")\n",
    "        plt.ylabel(\"True spectral type\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.bar(np.arange(13), height = self.f1_test[:13], tick_label = star_class_labels ,label = \"F1 score\")\n",
    "        plt.axhline(self.f1_mean_test, color='red', linestyle='--', label = 'F1 score average')\n",
    "        plt.axhline(self.success_rate_test, color='purple', label = 'Success rate')\n",
    "        plt.xlabel(\"Spectral class\")\n",
    "        plt.ylabel(\"Metric\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet5-like network\n",
    "architecture = tf.keras.Sequential([ \n",
    "    layers.Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', input_shape = (32,32,1)),\n",
    "    layers.MaxPooling2D((2,2)), #The original version has average pooling\n",
    "    \n",
    "    layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)), #The original version has average pooling\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation = 'relu'),\n",
    "    layers.Dense(84, activation = 'relu'),\n",
    "    layers.Dense(13, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "model3 = CNN_model(train_dataset, test_dataset, architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.train_model(training_epochs= 100, learning_rate= 0.001, patience_epochs= 0)\n",
    "model3.predict_val()\n",
    "model3.predict_test()\n",
    "model3.plot_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested by chatGPT\n",
    "architecture = tf.keras.Sequential([\n",
    "    layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (32,32,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3), activation = 'relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(13, activation = 'softmax')\n",
    "])\n",
    "architecture.summary()\n",
    "\n",
    "model4 = CNN_model(train_dataset, test_dataset, architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.train_model(training_epochs= 100, learning_rate= 0.001, patience_epochs= 0)\n",
    "model4.predict_val()\n",
    "model4.predict_test()\n",
    "model4.plot_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet unfinished attempt\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 1))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "architecture = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(13, activation = 'softmax')\n",
    "])\n",
    "architecture.summary()\n",
    "model5 = CNN_model(train_dataset, test_dataset, architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.train_model(training_epochs= 100, learning_rate= 0.001, patience_epochs= 0)\n",
    "model5.predict_val()\n",
    "model5.predict_test()\n",
    "model5.plot_training_evolution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
