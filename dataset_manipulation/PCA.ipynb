{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs PCA on the stars of a dataset and saves it into a new dataset containing only the necessary variables for classification\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "test_dataset = np.load(data_path + 'test_Euclid_res_20000_TestStars_id_002GT_100_bins.npy', allow_pickle=True)[()]\n",
    "train_dataset = np.load(data_path + 'train_Euclid_res_52000_TrainStars_id_002GT_100_bins.npy', allow_pickle=True)[()]\n",
    "output_path = data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stars\n",
    "\n",
    "noiseless_train_stars = train_dataset['stars']\n",
    "noiseless_test_stars = test_dataset['stars']\n",
    "noisy_train_stars = train_dataset['noisy_stars']\n",
    "noisy_test_stars = test_dataset['noisy_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_PCA(N_components, fit_selection, *transform_selection):\n",
    "    \"\"\"Performs PCA decomposition on star sets and returns a PCA star sets.\n",
    "\n",
    "    Args:\n",
    "        N_components (int): Number of PCA components to do the analysis.\n",
    "        fit_selection: Star set (in 32x32 float array format) to do the PCA fit.\n",
    "        transform_selection: Variable amount of star sets to do the PCA transform on.\n",
    "        \n",
    "    Returns: \n",
    "        List: Processed PCA star sets.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components= N_components) \n",
    "    pca.fit(fit_selection.reshape(-1, 1024))\n",
    "\n",
    "    pca_processed_sets = []\n",
    "    for i in range(len(transform_selection)):\n",
    "        pca_processed_sets.append(pca.transform(transform_selection[i].reshape(-1, 1024)))\n",
    "\n",
    "    return pca_processed_sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "y_test = SEDlisttoC(test_dataset['SED_ids'])\n",
    "sed_test = test_dataset['SED_ids']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways of doing PCA\n",
    "- A: fit and transform both noiseless train and test sets \n",
    "- B: fit and transform both noisy train and test sets\n",
    "- C: fit noiseless train and test sets, transform noisy train and test sets\n",
    "- D: fit and transform both noisy train and test sets with SNR >= 50\n",
    "- E: fit and transform noisy train set, fit and transform noisy test set\n",
    "\n",
    "The chosen method was B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset A\n",
    "\n",
    "fit_selection = np.concatenate((noiseless_train_stars, noiseless_test_stars), axis = 0)\n",
    "x_train, x_test = perform_PCA(fit_selection, noiseless_train_stars, noiseless_test_stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset B\n",
    "\n",
    "fit_selection = np.concatenate((noisy_train_stars, noisy_test_stars), axis = 0)\n",
    "PCA_components = [12, 15, 18, 21, 24, 27, 30, 33]\n",
    "\n",
    "for N_components in PCA_components:\n",
    "    x_train, x_test = perform_PCA(N_components, fit_selection, noisy_train_stars, noisy_test_stars)\n",
    "    y_train = SEDlisttoC(train_dataset['SED_ids'])\n",
    "    x_train, x_val, y_train, y_val, sed_train, sed_val = train_test_split(x_train, y_train, train_dataset['SED_ids'],test_size = 20000, shuffle = False) # Reserve 20,000 stars for validation\n",
    "\n",
    "    PCA_dataset = {\n",
    "        'train_stars_pca' : x_train,\n",
    "        'validation_stars_pca' : x_val,\n",
    "        'test_stars_pca' : x_test,\n",
    "        'train_C' : y_train,\n",
    "        'validation_C' : y_val,\n",
    "        'test_C' : y_test,\n",
    "        'train_SEDs': sed_train,\n",
    "        'validation_SEDs' : sed_val,\n",
    "        'test_SEDs' : sed_test,\n",
    "        'N_components' : N_components\n",
    "    }\n",
    "\n",
    "    np.save(\n",
    "        output_path + 'PCA_dataset2B'+ str(N_components)+'.npy',\n",
    "        PCA_dataset,\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
