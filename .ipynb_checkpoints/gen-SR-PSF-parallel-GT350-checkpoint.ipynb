{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dabcd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wf_psf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwf_psf\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwf_psf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed, cpu_count, parallel_backend\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wf_psf'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wf_psf as wf_psf\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed, cpu_count, parallel_backend\n",
    "\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "# SED folder path\n",
    "# SED_path = '/feynman/work/dap/lcs/ec270266/wf-psf/data/SEDs/save_SEDs/'\n",
    "SED_path = '/local/home/as274094/Desktop/Code/wf-psf/data/SEDs/save_SEDs/'\n",
    "\n",
    "# Output saving path (in node05 of candide or $WORK space on feynman)\n",
    "# output_folder = '/feynman/work/dap/lcs/ec270266/output/interp_SEDs/'\n",
    "output_folder = '/local/home/as274094/Desktop/Code/psf_dataset/'\n",
    "\n",
    "# Reference dataset PATH\n",
    "# reference_data = '../interp_SED_data/reference_dataset/'\n",
    "reference_data = '/local/home/as274094/Desktop/Code/wf-psf/data/coherent_euclid_dataset/'\n",
    "ref_train = 'train_Euclid_res_2000_TrainStars_id_001.npy'\n",
    "ref_test  = 'test_Euclid_res_id_001.npy'\n",
    "selected_id_SED_path = 'selected_id_SED.npy'\n",
    "\n",
    "# Number of cpus to use for parallelization\n",
    "n_cpus = 2 # 24\n",
    "\n",
    "# Save output prints to logfile\n",
    "old_stdout = sys.stdout\n",
    "log_file = open(output_folder + 'output.log','w')\n",
    "sys.stdout = log_file\n",
    "print('Starting the log file.')\n",
    "\n",
    "# Dataset ID\n",
    "dataset_id = 9\n",
    "dataset_id_str = '%03d'%(dataset_id)\n",
    "\n",
    "# This list must be in order from bigger to smaller\n",
    "n_star_list = [4] # [2000]\n",
    "n_test_stars = 2 # 400  # 20% of the max test stars\n",
    "# Total stars\n",
    "n_stars = n_star_list[0] + n_test_stars\n",
    "# Max train stars\n",
    "tot_train_stars = n_star_list[0]\n",
    "\n",
    "# Parameters\n",
    "d_max = 2\n",
    "max_order = 45\n",
    "x_lims = [0, 1e3]\n",
    "y_lims = [0, 1e3]\n",
    "grid_points = [4, 4]\n",
    "n_bins = 10 # 350\n",
    "auto_init = False\n",
    "verbose = True\n",
    "\n",
    "oversampling_rate = 3.\n",
    "output_Q = 3.\n",
    "\n",
    "max_wfe_rms = 0.1\n",
    "output_dim = 32\n",
    "LP_filter_length = 2\n",
    "euclid_obsc = True\n",
    "\n",
    "# Values for getting 3xEuclid_resolution PSFs outputs.\n",
    "original_out_Q = output_Q\n",
    "original_out_dim = output_dim\n",
    "super_out_Q = 1\n",
    "super_out_res = 64\n",
    "\n",
    "# Desired WFE resolutions\n",
    "WFE_resolutions = [256]\n",
    "\n",
    "print('\\nInit dataset generation')\n",
    "\n",
    "zernikes_multires = []\n",
    "sim_PSF_toolkit_multires = []\n",
    "gen_poly_fieldPSF_multires = []\n",
    "\n",
    "for i, pupil_diameter_ in tqdm(enumerate(WFE_resolutions)):\n",
    "\n",
    "    # Generate Zernike maps in max resolution\n",
    "    zernikes_multires.append(\n",
    "        wf_psf.utils.zernike_generator(\n",
    "            n_zernikes=max_order,\n",
    "            wfe_dim=pupil_diameter_\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Initialize PSF simulator for each cpu available \n",
    "    # (no euclid obscurations and wfr_rms init)\n",
    "    packed_PSFToolkit = [wf_psf.SimPSFToolkit(\n",
    "        zernikes_multires[i],\n",
    "        max_order=max_order,\n",
    "        max_wfe_rms=max_wfe_rms,\n",
    "        oversampling_rate=oversampling_rate,\n",
    "        output_Q=output_Q,\n",
    "        output_dim=output_dim,\n",
    "        pupil_diameter=pupil_diameter_,\n",
    "        euclid_obsc=euclid_obsc,\n",
    "        LP_filter_length=LP_filter_length\n",
    "    ) for j in range(n_cpus)]\n",
    "    sim_PSF_toolkit_multires.append(packed_PSFToolkit)\n",
    "\n",
    "    # Initialize one PSF field for each resolution\n",
    "    packed_polyField_PSF = [wf_psf.GenPolyFieldPSF(\n",
    "        sim_PSF_toolkit_multires[i][j],\n",
    "        d_max=d_max,\n",
    "        grid_points=grid_points,\n",
    "        max_order=max_order,\n",
    "        x_lims=x_lims,\n",
    "        y_lims=y_lims,\n",
    "        n_bins=n_bins,\n",
    "        lim_max_wfe_rms=max_wfe_rms,\n",
    "        auto_init=auto_init,\n",
    "        verbose=verbose\n",
    "    ) for j in range(n_cpus)]\n",
    "    gen_poly_fieldPSF_multires.append(packed_polyField_PSF)\n",
    "    \n",
    "\n",
    "# # Dummy SimPSFToolkit to init obscurations\n",
    "# init_toolkit = []\n",
    "# init_polyField = []\n",
    "# for i, pupil_diameter_ in enumerate(WFE_resolutions):\n",
    "#     init_toolkit.append( wf_psf.SimPSFToolkit(\n",
    "#         zernikes_multires[i], max_order=max_order, max_wfe_rms=max_wfe_rms, oversampling_rate=oversampling_rate,\n",
    "#         output_Q=output_Q, output_dim=output_dim, pupil_diameter=pupil_diameter_, euclid_obsc=euclid_obsc,\n",
    "#         LP_filter_length=LP_filter_length) )\n",
    "#     init_polyField.append( wf_psf.GenPolyFieldPSF(init_toolkit[i], d_max=d_max,\n",
    "#         grid_points=grid_points, max_order=max_order,\n",
    "#         x_lims=x_lims, y_lims=y_lims, n_bins=n_bins,\n",
    "#         lim_max_wfe_rms=max_wfe_rms, auto_init=True, verbose=verbose))\n",
    "\n",
    "# # Share C_poly coefficients throughout all the different resolution models\n",
    "# for i in range(len(gen_poly_fieldPSF_multires)):\n",
    "#     for j in range(n_cpus):\n",
    "#         gen_poly_fieldPSF_multires[i][j].set_C_poly(init_polyField[0].C_poly)\n",
    "#         gen_poly_fieldPSF_multires[i][j].set_WFE_RMS(init_polyField[0].WFE_RMS)\n",
    "#         gen_poly_fieldPSF_multires[i][j].sim_psf_toolkit.obscurations = init_toolkit[i].obscurations\n",
    "\n",
    "# Load reference dataset\n",
    "selected_id_SED = np.load(reference_data+'selected_id_SED.npy', allow_pickle=True)\n",
    "train_dataset_ref = np.load(reference_data+ref_train, allow_pickle=True)[()]\n",
    "test_dataset_ref = np.load(reference_data+ref_test, allow_pickle=True)[()]\n",
    "\n",
    "# Load the SEDs\n",
    "stellar_SEDs = np.load(SED_path + 'SEDs.npy', allow_pickle=True)\n",
    "stellar_lambdas = np.load(SED_path + 'lambdas.npy', allow_pickle=True)\n",
    "\n",
    "# Load all the stars positions\n",
    "pos_np = np.vstack((train_dataset_ref['positions'],test_dataset_ref['positions']))\n",
    "# Assign SEDs\n",
    "SED_list = []\n",
    "for it in range(n_stars):\n",
    "    concat_SED_wv = np.concatenate((\n",
    "        stellar_lambdas.reshape(-1,1),\n",
    "        stellar_SEDs[selected_id_SED[it],:].reshape(-1,1)\n",
    "    ), axis=1)\n",
    "    SED_list.append(concat_SED_wv)\n",
    "\n",
    "# Load and assign the C_poly matrix\n",
    "C_poly = train_dataset_ref['C_poly']\n",
    "for i in range(len(gen_poly_fieldPSF_multires)):\n",
    "    for j in range(n_cpus):\n",
    "        gen_poly_fieldPSF_multires[i][j].set_C_poly(C_poly)\n",
    "\n",
    "print('\\nStar positions selected')\n",
    "\n",
    "#######################################\n",
    "#            PARALELLIZED             #\n",
    "#######################################\n",
    "\n",
    "# Total number of stars\n",
    "n_procs = n_stars*len(WFE_resolutions)\n",
    "\n",
    "# Print some info\n",
    "cpu_info = ' - Number of available CPUs: {}'.format(n_cpus)\n",
    "proc_info = ' - Total number of processes: {}'.format(n_procs)\n",
    "print(cpu_info)\n",
    "print(proc_info)\n",
    "\n",
    "# Generate star list\n",
    "star_id_list = [id_ for id_ in range(n_stars)]\n",
    "\n",
    "# Function to get (i,j) from id\n",
    "def unwrap_id(id, n_stars):\n",
    "    i = int(id/n_stars)\n",
    "    j = int(id - i * n_stars)\n",
    "    return i, j\n",
    "\n",
    "def print_status(star_id, i, j):\n",
    "    print('\\nStar ' +str(star_id)+ ' done!' + '   index=('+str(i)+','+str(j)+')')\n",
    "\n",
    "# Get batches from a list\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "# Function to get one PSF\n",
    "def simulate_star(star_id, gen_poly_fieldPSF_multires,i):\n",
    "    i_,j_ = unwrap_id(star_id, n_cpus)\n",
    "    _psf, _zernike, _ = gen_poly_fieldPSF_multires[i][j_].get_poly_PSF(\n",
    "        xv_flat=pos_np[star_id, 0],\n",
    "        yv_flat=pos_np[star_id, 1],\n",
    "        SED=SED_list[star_id]\n",
    "    )\n",
    "    # Change output parameters to get the super resolved PSF\n",
    "    gen_poly_fieldPSF_multires[i][j_].sim_psf_toolkit.output_Q = super_out_Q\n",
    "    gen_poly_fieldPSF_multires[i][j_].sim_psf_toolkit.output_dim = super_out_res\n",
    "    super_psf, _, _ = gen_poly_fieldPSF_multires[i][j_].get_poly_PSF(\n",
    "        xv_flat=pos_np[star_id, 0],\n",
    "        yv_flat=pos_np[star_id, 1],\n",
    "        SED=SED_list[star_id]\n",
    "    )\n",
    "    # Put back original parameters\n",
    "    gen_poly_fieldPSF_multires[i][j_].sim_psf_toolkit.output_Q = original_out_Q\n",
    "    gen_poly_fieldPSF_multires[i][j_].sim_psf_toolkit.output_dim = original_out_dim\n",
    "    #print_status(star_id, i, star_id)\n",
    "    return (star_id, _psf, _zernike, super_psf)\n",
    "\n",
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "zernike_coef_multires = []\n",
    "poly_psf_multires = []\n",
    "index_multires = []\n",
    "super_psf_multires = []\n",
    "\n",
    "for i in range(len(WFE_resolutions)):\n",
    "    index_i_list = []\n",
    "    psf_i_list = []\n",
    "    z_coef_i_list = []\n",
    "    super_psf_i_list = []\n",
    "    for batch in chunker(star_id_list, n_cpus):\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            results = Parallel(n_jobs=n_cpus, verbose=100)(delayed(simulate_star)(_star_id, gen_poly_fieldPSF_multires,i)\n",
    "                                                for _star_id in batch)\n",
    "        index_batch,psf_batch,z_coef_batch,super_psf_batch = zip(*results)\n",
    "        index_i_list.extend(index_batch)\n",
    "        psf_i_list.extend(psf_batch)\n",
    "        z_coef_i_list.extend(z_coef_batch)\n",
    "        super_psf_i_list.extend(super_psf_batch)\n",
    "\n",
    "    index_multires.append(np.array(index_i_list) )\n",
    "    poly_psf_multires.append(np.array( psf_i_list)) \n",
    "    zernike_coef_multires.append(np.array(z_coef_i_list))\n",
    "    super_psf_multires.append(np.array(super_psf_i_list))\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\nAll stars generated in '+ str(end_time-start_time) +' seconds')\n",
    "\n",
    "#######################################\n",
    "#            END PARALLEL             #\n",
    "#######################################\n",
    "\n",
    "# Add noise to generated PSFs and save datasets\n",
    "\n",
    "# SNR varying randomly from 10 to 120 - shared over all WFE resolutions\n",
    "rand_SNR = (np.random.rand(tot_train_stars) * 100) + 10\n",
    "# Copy the training stars\n",
    "train_stars = np.copy(np.array(poly_psf_multires[0])[:tot_train_stars, :, :])\n",
    "# Add Gaussian noise to the observations\n",
    "noisy_train_stars = np.stack([wf_psf.utils.add_noise(_im, desired_SNR=_SNR) \n",
    "                              for _im, _SNR in zip(train_stars, rand_SNR)], axis=0)\n",
    "# Generate Gaussian noise patterns to be shared over all datasets (but not every star)\n",
    "noisy_train_patterns = noisy_train_stars - train_stars\n",
    "\n",
    "WFE_res_id = 0\n",
    "\n",
    "# Generate datasets for every WFE resolution\n",
    "for poly_psf_np, zernike_coef_np, super_psf_np in zip(poly_psf_multires, zernike_coef_multires, super_psf_multires):\n",
    "    \n",
    "    # Generate numpy array from the SED list\n",
    "    SED_np = np.array(SED_list)\n",
    "\n",
    "    # Add same noise dataset to each WFE-resolution dataset\n",
    "    noisy_train_stars = np.copy(poly_psf_np[:tot_train_stars, :, :]) + noisy_train_patterns\n",
    "\n",
    "    # Save only one test dataset\n",
    "    # Build param dicitionary\n",
    "    dataset_params = {\n",
    "        'd_max':d_max,\n",
    "        'max_order':max_order,\n",
    "        'x_lims':x_lims,\n",
    "        'y_lims':y_lims,\n",
    "        'grid_points':grid_points,\n",
    "        'n_bins':n_bins,\n",
    "        'max_wfe_rms':max_wfe_rms,\n",
    "        'oversampling_rate':oversampling_rate,\n",
    "        'output_Q':output_Q,\n",
    "        'output_dim':output_dim,\n",
    "        'LP_filter_length':LP_filter_length,\n",
    "        'pupil_diameter':WFE_resolutions[WFE_res_id],\n",
    "        'euclid_obsc':euclid_obsc,\n",
    "        'n_stars':n_test_stars\n",
    "    }\n",
    "\n",
    "    # Save dataset C coefficient matrix (reproductible dataset)\n",
    "    C_poly = gen_poly_fieldPSF_multires[WFE_res_id][n_cpus-1].C_poly\n",
    "\n",
    "    test_psf_dataset = {\n",
    "        'stars' : poly_psf_np[tot_train_stars:, :, :],\n",
    "        'super_res_stars' : super_psf_np[tot_train_stars:, :, :],\n",
    "        'positions' : pos_np[tot_train_stars:, :],\n",
    "        'SEDs' : SED_np[tot_train_stars:, :, :],\n",
    "        'zernike_coef' : zernike_coef_np[tot_train_stars:, :, :],\n",
    "        'C_poly' : C_poly,\n",
    "        'parameters': dataset_params\n",
    "    }\n",
    "\n",
    "    np.save(\n",
    "        output_folder + 'test_Euclid_res_id_' + dataset_id_str + 'GT_350_bins.npy',\n",
    "        test_psf_dataset,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Save the different train datasets\n",
    "    for it_glob in range(len(n_star_list)):\n",
    "\n",
    "        n_train_stars = n_star_list[it_glob]\n",
    "\n",
    "        # Build param dicitionary #/local/home/as274094/Desktop/Code/wf-psf/data/coherent_euclid_dataset/?\n",
    "        dataset_params = {\n",
    "            'd_max':d_max,\n",
    "            'max_order':max_order,\n",
    "            'x_lims':x_lims,\n",
    "            'y_lims':y_lims,\n",
    "            'grid_points':grid_points,\n",
    "            'n_bins':n_bins,\n",
    "            'max_wfe_rms':max_wfe_rms,\n",
    "            'oversampling_rate':oversampling_rate,\n",
    "            'output_Q':output_Q,\n",
    "            'output_dim':output_dim,\n",
    "            'LP_filter_length':LP_filter_length,\n",
    "            'pupil_diameter':WFE_resolutions[WFE_res_id],\n",
    "            'euclid_obsc':euclid_obsc,\n",
    "            'n_stars':n_train_stars\n",
    "        }\n",
    "\n",
    "        train_psf_dataset = {\n",
    "            'stars' : poly_psf_np[:n_train_stars, :, :],\n",
    "            'noisy_stars': noisy_train_stars[:n_train_stars, :, :],\n",
    "            'super_res_stars' : super_psf_np[:n_train_stars, :, :],\n",
    "            'positions' : pos_np[:n_train_stars, :],\n",
    "            'SEDs' : SED_np[:n_train_stars, :, :],\n",
    "            'zernike_coef' : zernike_coef_np[:n_train_stars, :, :],\n",
    "            'C_poly' : C_poly,\n",
    "            'parameters': dataset_params\n",
    "        }\n",
    "\n",
    "\n",
    "        np.save(\n",
    "            output_folder + 'train_Euclid_res_' + str(n_train_stars) + '_TrainStars_id_' + dataset_id_str + 'GT_350_bins.npy',\n",
    "            train_psf_dataset,\n",
    "            allow_pickle=True\n",
    "        )\n",
    "\n",
    "    # Next desired resolution   \n",
    "    WFE_res_id += 1\n",
    "\n",
    "print('\\nDone!')\n",
    "\n",
    "# Close log file\n",
    "sys.stdout = old_stdout\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
