{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 11:10:48.228076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "output_folder = '/Users/as274094/GitHub/psf_dataset_generation/output/'\n",
    "test_dataset = np.load(output_folder + 'test_Euclid_res_10_TestStars_id_001GT_100_bins.npy', allow_pickle=True)[()]\n",
    "train_dataset = np.load(output_folder + '/train_Euclid_res_50_TrainStars_id_001GT_100_bins.npy', allow_pickle=True)[()]\n",
    "train_stars = train_dataset['stars']\n",
    "test_stars = test_dataset['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "PCA_components = 24\n",
    "model_learning_rate = 0.1\n",
    "N_epochs = 50\n",
    "N_committee = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "train_C = SEDlisttoC(train_dataset['SED_ids'])\n",
    "test_C = SEDlisttoC(test_dataset['SED_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_SED_original = np.random.randint(low = 0, high = 13, size = 50)\n",
    "example_C = SEDlisttoC(example_SED_original)\n",
    "example_C_noisy = example_C + np.random.rand(example_C.shape[0])*0.8-0.40\n",
    "example_SED_obtained = CtoSEDarray(example_C_noisy)\n",
    "for i in range(example_SED_original.shape[0]):\n",
    "    print(example_SED_original[i], example_C_noisy[i], example_SED_obtained[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on all the images\n",
    "pca = PCA(n_components= PCA_components)\n",
    "train_and_test_stars = np.concatenate((train_stars, test_stars), axis = 0)\n",
    "pca.fit(train_and_test_stars.reshape(-1, 1024))\n",
    "x_train = pca.transform(train_stars.reshape(-1, 1024))\n",
    "x_test = pca.transform(test_stars.reshape(-1, 1024))\n",
    "y_train = train_C\n",
    "x_train, x_val, y_train, y_val = train_test_split( x_train, y_train, test_size = 20) # Reserve 20,000 stars for validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed = 1)\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(26, input_shape=[PCA_components], activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(1, activation = 'linear', kernel_initializer= initializer)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = model_learning_rate)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train a committee of 48 neural networks and make predictions\n",
    "committee = []\n",
    "committee_predictions = []\n",
    "for i in range(N_committee):\n",
    "    model = create_model()\n",
    "    model.fit(x_train, y_train, epochs= N_epochs, verbose=0)\n",
    "    committee.append(model)\n",
    "    committee_predictions.append(model.predict(x_test).reshape(-1)) # Predict the scalar parameter C using the committee    \n",
    "\n",
    "committee_predictions = np.array(committee_predictions)\n",
    "y_pred = np.mean(committee_predictions, axis=0)\n",
    "pred_variance = np.var(committee_predictions, axis=0)\n",
    "SED_pred = CtoSEDarray(y_pred,pred_variance)\n",
    "#add metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 12), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.math.confusion_matrix(test_dataset['SED_ids'], SED_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the committee\n",
    "\n",
    "mse = np.mean((test_C - y_pred)**2)\n",
    "print('MSE:', mse)\n",
    "print(pred_variance)\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    print(test_dataset['SED_ids'][i], y_pred[i], SED_pred[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
