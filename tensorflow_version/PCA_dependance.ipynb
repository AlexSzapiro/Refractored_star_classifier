{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.metrics as skm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "# data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset2/'\n",
    "#data_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "PCA_components = 24\n",
    "model_learning_rate = 0.1\n",
    "N_epochs = 100\n",
    "N_committee = 48\n",
    "patience_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "\n",
    "completion_callback = TrainingCompletionCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_model:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "        dataset = np.load(data_path + dataset_name + \".npy\", allow_pickle=True)[()]\n",
    "        self.x_train = dataset['train_stars_pca']\n",
    "        self.x_val = dataset['validation_stars_pca']\n",
    "        self.x_test = dataset['test_stars_pca']\n",
    "        self.y_train = dataset['train_C']\n",
    "        self.y_val = dataset['validation_C']\n",
    "        self.y_test = dataset['test_C']\n",
    "        self.SED_val = dataset['validation_SEDs']\n",
    "        self.SED_test = dataset['test_SEDs']\n",
    "        \n",
    "    def create_model(self):\n",
    "        initializer = tf.keras.initializers.GlorotNormal(seed = None)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            layers.Dense(26, input_shape=[PCA_components], activation='sigmoid', kernel_initializer= initializer),\n",
    "            layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "            layers.Dense(1, activation = 'linear', kernel_initializer= initializer)\n",
    "        ])\n",
    "    \n",
    "    def train_model(self, learning_rate, training_epochs, patience_epochs):\n",
    "\n",
    "        self.model.compile(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        )\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "\n",
    "        start_time = time.time() # Measure training time\n",
    "        self.learning = self.model.fit(self.x_train, self.y_train, epochs= training_epochs, verbose = 0, callbacks = [completion_callback,early_stopping], validation_data=(self.x_val,self.y_val)) \n",
    "\n",
    "        # Calculate the training time\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n",
    "        print(\"Total training time:\", self.training_time, \"seconds\")\n",
    "\n",
    "    def predict_test(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_test, verbose = 1).reshape(-1)\n",
    "        SED_pred_test = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_test = np.mean((self.y_test - C_pred)**2)\n",
    "        self.f1_test = skm.f1_score(self.SED_test, SED_pred_test, average = None)\n",
    "        self.f1_mean_test = np.mean(self.f1_test[:13])\n",
    "        self.confusion_matrix_test = skm.confusion_matrix(self.SED_test, SED_pred_test)\n",
    "        self.success_rate_test = calculate_success_rate(self.confusion_matrix_test)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the test set\")\n",
    "            print('MSE:', self.mse_test)\n",
    "            print('\\nF1 score for each class:', self.f1_test)\n",
    "            print('Average F1 score:', self.f1_mean_test)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_test)\n",
    "            print('\\nSuccess rate:', self.success_rate_test)\n",
    "\n",
    "\n",
    "    def predict_val(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_val, verbose = 1).reshape(-1)\n",
    "        SED_pred_val = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_val = np.mean((self.y_val - C_pred)**2) \n",
    "        self.f1_val = skm.f1_score(self.SED_val, SED_pred_val, average = None)\n",
    "        self.f1_mean_val = np.mean(self.f1_val[:13])\n",
    "        self.confusion_matrix_val = skm.confusion_matrix(self.SED_val, SED_pred_val)\n",
    "        self.success_rate_val = calculate_success_rate(self.confusion_matrix_val)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the validation set\")\n",
    "            print('MSE:', self.mse_val)\n",
    "            print('\\nF1 score for each class:', self.f1_val)\n",
    "            print('Average F1 score:', self.f1_mean_val)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_val)\n",
    "            print('\\nSuccess rate:', self.success_rate_val)\n",
    "\n",
    "    def save_model(self):\n",
    "        os.makedirs(\"single_models\", exist_ok=True)\n",
    "        self.model.save(f\"single_models/my_model_{self.dataset_name}.h5\")\n",
    "\n",
    "    def plot_loss(self):\n",
    "    # Plot the loss function evolution\n",
    "\n",
    "        loss_evolution = self.learning.history[\"loss\"]\n",
    "        val_loss_evolution = self.learning.history[\"val_loss\"]\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.plot(loss_evolution,label = \"Train set\")\n",
    "        plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss function value\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss function evolution\")\n",
    "        print(\"Total training time:\", self.training_time, \"seconds\")\n",
    "        print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n",
    "\n",
    "    def plot_cf_matrix(self):\n",
    "        # Plot the confusion matrix\n",
    "\n",
    "        star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "        plt.figure(figsize= (12,10))\n",
    "        heatmap = plt.imshow(self.confusion_matrix_test[:13,:], cmap='Blues')\n",
    "        plt.xticks(np.arange(14), star_class_labels + ['???'])\n",
    "        plt.yticks(np.arange(13), star_class_labels)\n",
    "        plt.colorbar(heatmap)\n",
    "        plt.xlabel(\"Estimated spectral type\")\n",
    "        plt.ylabel(\"True spectral type\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A','B','C','D','E']\n",
    "\n",
    "model_list = []\n",
    "for letter in letters:\n",
    "    model = PCA_model('PCA_dataset2' + letter)\n",
    "    model.create_model()\n",
    "    model.train_model(training_epochs= 12, learning_rate=model_learning_rate, patience_epochs=patience_epochs)\n",
    "    model.predict_test()\n",
    "    model.predict_val()\n",
    "    model_list.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = model_list[1]\n",
    "\n",
    "# Plot the loss function evolution\n",
    "\n",
    "loss_evolution = modelB.learning.history[\"loss\"][10:]\n",
    "val_loss_evolution = modelB.learning.history[\"val_loss\"][10:]\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.plot(loss_evolution,label = \"Train set\")\n",
    "plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss function value\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss function evolution\")\n",
    "print(\"Total training time:\", modelB.training_time, \"seconds\")\n",
    "print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.train_model(training_epochs= 100, learning_rate= 0.005, patience_epochs= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function evolution\n",
    "\n",
    "model_list[0].plot_cf_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.predict_val()\n",
    "modelB.predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in model_list:\n",
    "    metrics.append([model.success_rate_test, model.f1_mean_test, model.success_rate_val, model.f1_mean_val])\n",
    "metrics = np.array(metrics)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics of the different datasets\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (18,10))\n",
    "\n",
    "ax.scatter(letters, metrics[:,0],label = \"Success rate test\", color = 'red', marker= \"x\", s = 100)\n",
    "ax.scatter(letters, metrics[:,2],label = \"Success rate validation\", color = 'blue', marker= \"x\", s = 100)\n",
    "ax.scatter(letters, metrics[:,1] ,label = \"F1 score test \", color = 'red', s = 100)\n",
    "ax.scatter(letters, metrics[:,3] ,label = \"F1 score validation \", color = 'blue', s = 100)\n",
    "\n",
    "ax.set_xlabel(\"PCA dataset\", fontsize = 20)\n",
    "ax.set_ylabel(\"Metric\", fontsize = 20)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.grid(True)\n",
    "ax.legend(fontsize = 12)\n",
    "ax.set_title('Performance of different PCA decomposition methods', fontsize = 25)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
