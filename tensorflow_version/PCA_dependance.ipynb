{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.metrics as skm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "# data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "\n",
    "completion_callback = TrainingCompletionCallback()\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_model:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "        dataset = np.load(data_path + dataset_name + \".npy\", allow_pickle=True)[()]\n",
    "        self.PCA_components = dataset['N_components']\n",
    "        self.x_train = dataset['train_stars_pca']\n",
    "        self.x_val = dataset['validation_stars_pca']\n",
    "        self.x_test = dataset['test_stars_pca']\n",
    "        self.y_train = dataset['train_C']\n",
    "        self.y_val = dataset['validation_C']\n",
    "        self.y_test = dataset['test_C']\n",
    "        self.SED_val = dataset['validation_SEDs']\n",
    "        self.SED_test = dataset['test_SEDs']\n",
    "        self.learning = []\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        self.model = tf.keras.Sequential([\n",
    "            layers.Dense(26, input_shape=[self.PCA_components], activation='sigmoid', kernel_initializer= initializer),\n",
    "            layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "            layers.Dense(1, activation = 'linear', kernel_initializer= initializer)\n",
    "        ])\n",
    "    \n",
    "    def train_model(self, learning_rate, training_epochs, patience_epochs):\n",
    "\n",
    "        self.model.compile(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        )\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "\n",
    "        learn = self.model.fit(self.x_train, self.y_train, epochs= training_epochs, verbose = 0,\n",
    "                                        callbacks = [completion_callback,early_stopping], validation_data=(self.x_val,self.y_val), shuffle=True) \n",
    "\n",
    "        self.learning.append(learn)\n",
    "\n",
    "    def predict_test(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_test, verbose = 0).reshape(-1)\n",
    "        SED_pred_test = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_test = np.mean((self.y_test - C_pred)**2)\n",
    "        self.f1_test = skm.f1_score(self.SED_test, SED_pred_test, average = None)\n",
    "        self.f1_mean_test = np.mean(self.f1_test[:13])\n",
    "        self.confusion_matrix_test = skm.confusion_matrix(self.SED_test, SED_pred_test)\n",
    "        self.success_rate_test = calculate_success_rate(self.confusion_matrix_test)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the test set\")\n",
    "            print('MSE:', self.mse_test)\n",
    "            print('\\nF1 score for each class:', self.f1_test)\n",
    "            print('Average F1 score:', self.f1_mean_test)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_test)\n",
    "            print('\\nSuccess rate:', self.success_rate_test)\n",
    "\n",
    "\n",
    "    def predict_val(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_val, verbose = 0).reshape(-1)\n",
    "        SED_pred_val = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_val = np.mean((self.y_val - C_pred)**2) \n",
    "        self.f1_val = skm.f1_score(self.SED_val, SED_pred_val, average = None)\n",
    "        self.f1_mean_val = np.mean(self.f1_val[:13])\n",
    "        self.confusion_matrix_val = skm.confusion_matrix(self.SED_val, SED_pred_val)\n",
    "        self.success_rate_val = calculate_success_rate(self.confusion_matrix_val)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the validation set\")\n",
    "            print('MSE:', self.mse_val)\n",
    "            print('\\nF1 score for each class:', self.f1_val)\n",
    "            print('Average F1 score:', self.f1_mean_val)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_val)\n",
    "            print('\\nSuccess rate:', self.success_rate_val)\n",
    "\n",
    "    def save_model(self):\n",
    "        os.makedirs(\"single_models\", exist_ok=True)\n",
    "        self.model.save(f\"single_models/my_model_{self.dataset_name}.h5\")\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        model_path = os.path.join(model_path, f'my_model_{self.dataset_name}.h5')\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "\n",
    "    def plot_loss(self):\n",
    "    # Plot the loss function evolution\n",
    "\n",
    "        loss_evolution = self.learning[-1].history[\"loss\"]\n",
    "        val_loss_evolution = self.learning[-1].history[\"val_loss\"]\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.plot(loss_evolution,label = \"Train set\")\n",
    "        plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss function value\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss function evolution\")\n",
    "        print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n",
    "\n",
    "    def plot_cf_matrix(self):\n",
    "        # Plot the confusion matrix\n",
    "\n",
    "        star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "        plt.figure(figsize= (12,10))\n",
    "        heatmap = plt.imshow(self.confusion_matrix_test[:13,:], cmap='Blues')\n",
    "        plt.xticks(np.arange(14), star_class_labels + ['???'])\n",
    "        plt.yticks(np.arange(13), star_class_labels)\n",
    "        plt.colorbar(heatmap)\n",
    "        plt.xlabel(\"Estimated spectral type\")\n",
    "        plt.ylabel(\"True spectral type\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "\n",
    "N_components = [12, 15, 18, 21, 24, 27, 30, 33]\n",
    "model_array = np.empty((len(N_components),10), dtype=object)\n",
    "\n",
    "total_start_time = time.time() # Measure training time\n",
    "for i in range(model_array.shape[0]):\n",
    "    print('Start of the training of PCA_dataset2B' + str(N_components[i]))\n",
    "    for j in range(model_array.shape[1]):\n",
    "        model = PCA_model('PCA_dataset2B' + str(N_components[i]))\n",
    "        model.create_model()\n",
    "\n",
    "        single_start_time = time.time()\n",
    "        model.train_model(training_epochs= 70, learning_rate= 0.1, patience_epochs= 10)\n",
    "        model.train_model(training_epochs= 100, learning_rate= 0.01, patience_epochs= 12)\n",
    "        single_end_time = time.time()\n",
    "        single_training_time = single_end_time - single_start_time\n",
    "        print(\"Model training time:\", single_training_time, \"seconds\")\n",
    "\n",
    "        model.predict_val(verbose=0)\n",
    "        model.predict_test(verbose=0)\n",
    "        model_array[i][j]= model\n",
    "    print('End of the training of PCA_dataset2B' + str(N_components[i]))\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(\"Total training time:\", total_training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the models\n",
    "N_components = [12, 15, 18, 21, 24, 27, 30, 33]\n",
    "model_array2 = np.empty((len(N_components),10), dtype=object)\n",
    "\n",
    "for i in range(model_array2.shape[0]):\n",
    "    for j in range(model_array2.shape[1]):\n",
    "        model = PCA_model('PCA_dataset2B' + str(N_components[i]))\n",
    "        model.model = tf.keras.models.load_model(f\"saved_models/config1/{model.dataset_name}/my_model_{j}.h5\")\n",
    "        model_array2[i][j] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict again\n",
    "for i in range(model_array2.shape[0]):\n",
    "    for j in range(model_array2.shape[1]):\n",
    "        model_array2[i][j].predict_val(verbose=False)\n",
    "        model_array2[i][j].predict_test(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the models\n",
    "for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = model_array[i][j]\n",
    "            #os.makedirs(\"saved_models/config1\", exist_ok=True)\n",
    "            model.model.save(f\"saved_models/config1/{model.dataset_name}/my_model_{j}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_list[0]\n",
    "\n",
    "# Plot the loss function evolution\n",
    "\n",
    "loss_evolution = model.learning[-1].history[\"loss\"]\n",
    "val_loss_evolution = model.learning[-1].history[\"val_loss\"]\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.plot(loss_evolution,label = \"Train set\")\n",
    "plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss function value\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss function evolution\")\n",
    "print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_metric(model_array, metric):\n",
    "    metric_array = np.zeros_like(model_array) \n",
    "\n",
    "    for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = model_array[i][j]\n",
    "            metric_array[i][j] = getattr(model, metric)\n",
    "    return metric_array\n",
    "\n",
    "def obtain_graph_values(model_array, metric):\n",
    "    metric_array = obtain_metric(model_array, metric)\n",
    "\n",
    "    mean_values = np.mean(metric_array, axis=1)\n",
    "    min_values = np.min(metric_array, axis=1)\n",
    "    max_values = np.max(metric_array, axis=1)  \n",
    "    error_min = mean_values - min_values\n",
    "    error_max = max_values - mean_values\n",
    "    return mean_values, error_min, error_max\n",
    "\n",
    "def obtain_best_models(model_array):\n",
    "    best_models = np.empty((model_array.shape[0],1), dtype = object)\n",
    "\n",
    "    F1_array = obtain_metric(model_array, 'f1_mean_test')\n",
    "    indexes = np.argmax(F1_array, axis=1)\n",
    "    print(indexes)\n",
    "    for N in range(model_array.shape[0]):\n",
    "        model = model_array[N][indexes[N]]\n",
    "        best_models[N] = model\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = obtain_best_models(model_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics (with error bars) of the different datasets with multiple\n",
    "\n",
    "mean_valuesSt, error_minSt, error_maxSt = obtain_graph_values(model_array, 'success_rate_test')\n",
    "mean_valuesF1t, error_minF1t, error_maxF1t = obtain_graph_values(model_array, 'f1_mean_test')\n",
    "mean_valuesSv, error_minSv, error_maxSv = obtain_graph_values(model_array, 'success_rate_val')\n",
    "mean_valuesF1v, error_minF1v, error_maxF1v = obtain_graph_values(model_array, 'f1_mean_val')\n",
    "\n",
    "\n",
    "# Generate x-axis values based on the first dimension of the arrays\n",
    "x_values = N_components \n",
    "\n",
    "plt.subplots(figsize = (18,10))\n",
    "# Plotting the graph\n",
    "plt.errorbar(x_values, mean_valuesSt, yerr=[error_minSt, error_maxSt], fmt='o', label = \"Success rate test\", color = 'red', linestyle = '-', linewidth=2)\n",
    "plt.errorbar(x_values, mean_valuesF1t, yerr=[error_minF1t, error_maxF1t], fmt='o', label = \"F1 score test\", color = 'blue',linestyle = '-', linewidth=2)\n",
    "#plt.errorbar(x_values, mean_valuesSv, yerr=[error_minSv, error_maxSv], fmt='o', label = \"Success rate validation\", color = 'red', linestyle = '--', linewidth=2)\n",
    "#plt.errorbar(x_values, mean_valuesF1v, yerr=[error_minF1v, error_maxF1v], fmt='o', label = \"F1 score validation \", color = 'blue', linestyle = '--', linewidth=2)\n",
    "\n",
    "plt.xlabel(\"PCA components\", fontsize = 20)\n",
    "plt.ylabel(\"Metric\", fontsize = 20)\n",
    "plt.xticks(N_components,N_components)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.title('Performance of the classifier in function of the number of PCA components', fontsize = 25)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
