{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 13:46:22.450201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "#data_path = '/Users/as274094/Documents/psf_dataset1/'\n",
    "#data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset1/'\n",
    "data_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/'\n",
    "dataset = np.load(data_path + 'PCA_dataset1.npy', allow_pickle=True)[()]\n",
    "\n",
    "x_train = dataset['train_stars_pca']\n",
    "x_val = dataset['validation_stars_pca']\n",
    "x_test = dataset['test_stars_pca']\n",
    "y_train = dataset['train_C']\n",
    "y_val = dataset['validation_C']\n",
    "y_test = dataset['test_C']\n",
    "SED_test = dataset['test_SEDs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "PCA_components = 24\n",
    "model_learning_rate = 0.1\n",
    "N_epochs = 10\n",
    "N_committee = 48\n",
    "patience_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network # 0\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.3534255027771\n",
      "Training network # 1\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 2\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425025939941\n",
      "Training network # 3\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.3889641761779785 , Final validation loss: 6.3534255027771\n",
      "Training network # 4\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 5\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 6\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 7\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 8\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 9\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 10\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425025939941\n",
      "Training network # 11\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 12\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 13\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 14\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 15\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 16\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 17\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 18\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.3534255027771\n",
      "Training network # 19\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 20\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 21\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 22\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 23\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 24\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.3534255027771\n",
      "Training network # 25\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 26\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.3889641761779785 , Final validation loss: 6.3534255027771\n",
      "Training network # 27\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 28\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 29\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 30\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 31\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 32\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.3889641761779785 , Final validation loss: 6.353425025939941\n",
      "Training network # 33\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 34\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 35\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 36\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 37\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 38\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 39\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 40\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 41\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 42\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.3534255027771\n",
      "Training network # 43\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.3534255027771\n",
      "Training network # 44\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.3534255027771\n",
      "Training network # 45\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388965129852295 , Final validation loss: 6.353425979614258\n",
      "Training network # 46\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Training network # 47\n",
      "Training completed. Number of epochs: 5 , Final training loss: 6.388964653015137 , Final validation loss: 6.353425979614258\n",
      "Total training time: 49.837448835372925 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed = None)\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(26, input_shape=[PCA_components], activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(1, activation = 'linear', kernel_initializer= initializer)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = model_learning_rate)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "completion_callback = TrainingCompletionCallback()\n",
    "\n",
    "start_time = time.time() # Measure training time\n",
    "\n",
    "# Train a committee of 48 neural networks\n",
    "committee = []\n",
    "for i in range(N_committee):\n",
    "    model = create_model()\n",
    "    print(\"Training network #\",i)\n",
    "    learning = model.fit(x_train, y_train, epochs= N_epochs, verbose = 0, callbacks = [completion_callback, early_stopping], validation_data=(x_val,y_val))\n",
    "    committee.append(model)   \n",
    "\n",
    "# Calculate the training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Total training time:\", training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained committee\n",
    "\n",
    "committee = []\n",
    "committee_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/committee_models'\n",
    "# Load each model in the committee\n",
    "for i in range(N_committee):\n",
    "    model_path = os.path.join(committee_path, f'model_{i}.h5')\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    committee.append(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "committee_predictions = []\n",
    "for model in committee:\n",
    "    committee_predictions.append(model.predict(x_test, verbose = 0).reshape(-1)) # Predict the scalar parameter C using the committee   \n",
    "\n",
    "committee_predictions = np.array(committee_predictions)\n",
    "y_pred = np.mean(committee_predictions, axis=0)\n",
    "pred_variance = np.var(committee_predictions, axis=0)\n",
    "SED_pred = CtoSEDarray(y_pred,pred_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.531458548152945\n",
      "Variance:  [4.7369515e-14 3.4058683e-12 3.1405989e-12 ... 8.3701934e-12 2.0463631e-12\n",
      " 8.1854523e-12]\n",
      "\n",
      "F1 score: [0.         0.         0.         0.         0.         0.\n",
      " 0.14255863 0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "0.010966048114875605\n",
      "\n",
      "Confusion matrix:\n",
      "tf.Tensor(\n",
      "[[   0    0    0    0    0    0 1520    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1526    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1570    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1579    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1515    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1535    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1535    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1569    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1479    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1555    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1525    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1487    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1605    0    0    0    0    0    0]], shape=(13, 13), dtype=int32)\n",
      "\n",
      "Success rate: 0.23195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the committee\n",
    "\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "print('MSE:', mse)\n",
    "print(\"Variance: \", pred_variance)\n",
    "\n",
    "f1 = f1_score(SED_test, SED_pred, average = None)\n",
    "f1_mean = np.mean(f1[:13])\n",
    "print('\\nF1 score:', f1)\n",
    "print('Average F1 score:', f1_mean)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(SED_test, SED_pred) \n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "success_rate = calculate_success_rate(confusion_matrix)\n",
    "print('\\nSuccess rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the committee models\n",
    "\n",
    "os.makedirs(\"committee_models\", exist_ok=True)\n",
    "\n",
    "for i, model in enumerate(committee):\n",
    "    model.save(f\"committee_models/model_{i}.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "plt.figure(figsize= (12,10))\n",
    "heatmap = plt.imshow(confusion_matrix[:13,:], cmap='crest')\n",
    "plt.xticks(np.arange(14), star_class_labels + ['???'])\n",
    "plt.yticks(np.arange(13), star_class_labels)\n",
    "plt.colorbar(heatmap)\n",
    "plt.xlabel(\"Estimated spectral type\")\n",
    "plt.ylabel(\"True spectral type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.bar(np.arange(13), height = f1[:13], tick_label = star_class_labels ,label = \"F1 score\")\n",
    "plt.axhline(f1_mean, color='red', linestyle='--', label = 'F1 score average')\n",
    "plt.axhline(success_rate, color='purple', label = 'Success rate')\n",
    "plt.xlabel(\"Spectral class\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the loss function evolution\n",
    "\n",
    "loss_evolution = learning.history[\"loss\"][10:]\n",
    "val_loss_evolution = learning.history[\"val_loss\"][10:]\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.plot(loss_evolution,label = \"Train set\")\n",
    "plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss function value\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss function evolution\")\n",
    "print(\"Total training time:\", training_time, \"seconds\")\n",
    "print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
