{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/as274094/Documents/psf_dataset1/'\n",
    "# data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset1/'\n",
    "dataset = np.load(data_path + 'PCA_dataset1.npy', allow_pickle=True)[()]\n",
    "\n",
    "x_train = dataset['train_stars_pca']\n",
    "x_val = dataset['validation_stars_pca']\n",
    "x_test = dataset['test_stars_pca']\n",
    "y_train = dataset['train_C']\n",
    "y_val = dataset['validation_C']\n",
    "y_test = dataset['test_C']\n",
    "SED_test = dataset['test_SEDs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "PCA_components = 24\n",
    "model_learning_rate = 0.1\n",
    "N_epochs = 10\n",
    "N_committee = 48\n",
    "patience_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed = 1)\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(26, input_shape=[PCA_components], activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "        layers.Dense(1, activation = 'linear', kernel_initializer= initializer)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = model_learning_rate)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "progbar_logger = tf.keras.callbacks.ProgbarLogger()\n",
    "\n",
    "start_time = time.time() # Measure training time\n",
    "\n",
    "# Train a committee of 48 neural networks\n",
    "committee = []\n",
    "for i in range(N_committee):\n",
    "    model = create_model()\n",
    "    learning = model.fit(x_train, y_train, epochs= N_epochs, verbose = 0,callbacks = [progbar_logger,early_stopping], validation_data=(x_val,y_val))\n",
    "    committee.append(model)   \n",
    "\n",
    "# Calculate the training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained committee\n",
    "\n",
    "committee = []\n",
    "committee_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/committee_models'\n",
    "# Load each model in the committee\n",
    "for i in range(N_committee):\n",
    "    model_path = os.path.join(committee_path, f'model_{i}.h5')\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    committee.append(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "committee_predictions = []\n",
    "for model in committee:\n",
    "    committee_predictions.append(model.predict(x_test, verbose = 0).reshape(-1)) # Predict the scalar parameter C using the committee   \n",
    "\n",
    "committee_predictions = np.array(committee_predictions)\n",
    "y_pred = np.mean(committee_predictions, axis=0)\n",
    "pred_variance = np.var(committee_predictions, axis=0)\n",
    "SED_pred = CtoSEDarray(y_pred,pred_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.531458548152945\n",
      "Variance:  [4.7369515e-14 3.4058683e-12 3.1405989e-12 ... 8.3701934e-12 2.0463631e-12\n",
      " 8.1854523e-12]\n",
      "\n",
      "F1 score: [0.         0.         0.         0.         0.         0.\n",
      " 0.14255863 0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "0.010966048114875605\n",
      "\n",
      "Confusion matrix:\n",
      "tf.Tensor(\n",
      "[[   0    0    0    0    0    0 1520    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1526    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1570    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1579    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1515    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1535    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1535    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1569    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1479    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1555    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1525    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1487    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1605    0    0    0    0    0    0]], shape=(13, 13), dtype=int32)\n",
      "\n",
      "Success rate: 0.23195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the committee\n",
    "\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "print('MSE:', mse)\n",
    "print(\"Variance: \", pred_variance)\n",
    "\n",
    "f1 = f1_score(SED_test, SED_pred, average = None)\n",
    "print('\\nF1 score:', f1)\n",
    "print(np.mean(f1[:13]))\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(SED_test, SED_pred) \n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "success_rate = calculate_success_rate(confusion_matrix)\n",
    "print('\\nSuccess rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the committee models\n",
    "\n",
    "os.makedirs(\"committee_models\", exist_ok=True)\n",
    "\n",
    "for i, model in enumerate(committee):\n",
    "    model.save(f\"committee_models/model_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the loss function evolution\n",
    "\n",
    "loss_evolution = learning.history[\"loss\"]\n",
    "val_loss_evolution = learning.history[\"val_loss\"]\n",
    "\n",
    "plt.plot(loss_evolution,label = \"Train set\")\n",
    "plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss function value\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss function evolution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.bar(np.arange(13), height = f1, tick_label = np.arange(13) +1 ,label = \"F1 score\")\n",
    "plt.axhline(f1_mean, color='red', linestyle='--', label = 'F1 score average')\n",
    "plt.axhline(success_rate, color='purple', label = 'Success rate')\n",
    "plt.xlabel(\"Spectral class\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
