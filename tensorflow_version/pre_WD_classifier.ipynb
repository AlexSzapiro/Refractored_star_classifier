{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 10:49:50.111407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Script that receives an unclassified PSF dataset and returns the dataset with the according SEDs\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA decomposition\n",
    "dataset_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "dataset_name = 'train_Euclid_res_52000_TrainStars_id_002GT_100_bins.npy'\n",
    "dataset_2 = np.load(dataset_path + dataset_name, allow_pickle=True)[()] # The dataset to classify\n",
    "dataset_1 = np.load('/Users/as274094/Documents/psf_dataset2/test_Euclid_res_20000_TestStars_id_002GT_100_bins.npy', allow_pickle=True)[()] # The other dataset in order to make the PCA\n",
    "#dataset_2 = np.load('/Users/as274094/Documents/psf_dataset2/train_Euclid_res_52000_TrainStars_id_002GT_100_bins.npy', allow_pickle=True)[()]\n",
    "\n",
    "# Load the stars\n",
    "noisy_stars_1 = dataset_1['noisy_stars']\n",
    "noisy_stars_2 = dataset_2['noisy_stars']\n",
    "\n",
    "#should I exclude the validation stars?\n",
    "\n",
    "fit_selection = np.concatenate((noisy_stars_1, noisy_stars_2), axis = 0)\n",
    "N_components = 30\n",
    "\n",
    "pca = PCA(n_components= N_components)\n",
    "pca.fit(fit_selection.reshape(-1, 1024))\n",
    "x_to_convert = pca.transform(noisy_stars_1.reshape(-1, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and make predictions\n",
    "\n",
    "model_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/best_models/config1_PCA_dataset2B30/'\n",
    "classifier = tf.keras.models.load_model(model_path)\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "    \n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "Average F1 score: 0.6576688863666695\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 811  642   33    5    2    0    0    0    0    0    0    0    0    1]\n",
      " [ 454  969   90   18    5    1    0    0    0    0    0    0    0    0]\n",
      " [  10  178  838  445   47    7    1    1    0    0    0    0    0    0]\n",
      " [   3   45  393  866  206   14    6    0    0    0    0    0    0    0]\n",
      " [   0    4   31  314  966  170   15    7    2    0    0    0    0    0]\n",
      " [   0    1    2   15  226 1017  289   39    8    1    1    0    0    0]\n",
      " [   0    0    0    3   33  297  860  277   27    5    1    0    0    0]\n",
      " [   0    0    0    0    3   18  161  742  607   71   10    0    0    0]\n",
      " [   0    0    0    0    2    5   68  427  886  156   10    0    0    0]\n",
      " [   0    0    0    0    0    1   12   80  710  671   44    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    3   34 1428   37    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0   44 1527    2    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    2 1536    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Success rate: 0.9661\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and calculate metrics\n",
    "\n",
    "C_pred = classifier.predict(x_to_convert, verbose = 1).reshape(-1) # Predict the scalar parameter C\n",
    "class_pred = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "f1_mean = np.mean(skm.f1_score(dataset_1['SED_ids'], class_pred, average = None)[:13])\n",
    "print('Average F1 score:', f1_mean)\n",
    "\n",
    "confusion_matrix = skm.confusion_matrix(dataset_1['SED_ids'], class_pred)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "success_rate = calculate_success_rate(confusion_matrix)\n",
    "print('\\nSuccess rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# Assign SEDs\n",
    "concatenated_SEDs = np.load('concatenated_SEDs.npy', allow_pickle=True)[()]\n",
    "\n",
    "SED_list = []\n",
    "for spectral_class in class_pred:\n",
    "    if spectral_class == 20:\n",
    "        concat_SED = concatenated_SEDs[0] # what sould I do about the anomalies?\n",
    "        print('a')\n",
    "    else:\n",
    "        concat_SED = concatenated_SEDs[spectral_class]\n",
    "    SED_list.append(concat_SED)\n",
    "SED_array = np.array(SED_list, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1['SEDs'] = SED_array \n",
    "dataset_1['SED_ids'] = class_pred\n",
    "dataset_1['F1'] = f1_mean\n",
    "dataset_1['success_rate'] = success_rate\n",
    "\n",
    "np.save(\n",
    "        dataset_path + 'assigned_' + dataset_name,\n",
    "        dataset_1,\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
