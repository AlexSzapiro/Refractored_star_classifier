{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.metrics as skm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset2/'\n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate\n",
    "\n",
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "        final_acc = self.model.history.history['categorical_accuracy'][-1]\n",
    "        final_val_acc = self.model.history.history['val_categorical_accuracy'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "        print(\"Final accuracy:\", final_acc, \"Final validation accuracy:\", final_val_acc)\n",
    "\n",
    "completion_callback = TrainingCompletionCallback()\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed = 25)\n",
    "\n",
    "star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "class softmax_model:\n",
    "    def __init__(self, dataset_name, architecture):\n",
    "        self.dataset_name = dataset_name\n",
    "        dataset = np.load(data_path + dataset_name + \".npy\", allow_pickle=True)[()]\n",
    "        self.PCA_components = dataset['N_components']\n",
    "        self.x_train = dataset['train_stars_pca']\n",
    "        self.x_val = dataset['validation_stars_pca']\n",
    "        self.x_test = dataset['test_stars_pca']\n",
    "        self.y_val = dataset['validation_SEDs']\n",
    "        self.y_test = dataset['test_SEDs']\n",
    "        self.y_train_cat = tf.keras.utils.to_categorical(dataset['train_SEDs'],num_classes = 13)\n",
    "        self.y_val_cat = tf.keras.utils.to_categorical(dataset['validation_SEDs'],num_classes = 13)\n",
    "        self.y_test_cat = tf.keras.utils.to_categorical(dataset['test_SEDs'],num_classes = 13)\n",
    "        self.learning = []\n",
    "        self.model = architecture\n",
    "        \n",
    "    \n",
    "    def train_model(self, learning_rate, training_epochs, patience_epochs):\n",
    "\n",
    "        self.model.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "            metrics = 'categorical_accuracy'\n",
    "        )\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "\n",
    "        learn = self.model.fit(self.x_train, self.y_train_cat, epochs= training_epochs, verbose = 0,\n",
    "                                        callbacks = [completion_callback,early_stopping], validation_data=(self.x_val,self.y_val_cat), shuffle=True) \n",
    "\n",
    "        self.learning.append(learn)\n",
    "\n",
    "    def predict_test(self, verbose = True):\n",
    "        y_test_pred = self.model.predict(self.x_test)\n",
    "        class_predictions = np.argmax(y_test_pred, axis = 1)\n",
    "\n",
    "        self.f1_test = skm.f1_score(self.y_test, class_predictions, average = None)\n",
    "        self.f1_mean_test = np.mean(self.f1_test[:13])\n",
    "        self.confusion_matrix_test = skm.confusion_matrix(self.y_test, class_predictions)\n",
    "        self.success_rate_test = calculate_success_rate(self.confusion_matrix_test)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the test set\")\n",
    "            print('Average F1 score:', self.f1_mean_test)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_test)\n",
    "            print('\\nSuccess rate:', self.success_rate_test)\n",
    "\n",
    "\n",
    "    def predict_val(self, verbose = True):\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        class_predictions = np.argmax(y_val_pred, axis = 1)\n",
    "\n",
    "        self.f1_val = skm.f1_score(self.y_val, class_predictions, average = None)\n",
    "        self.f1_mean_val = np.mean(self.f1_val[:13])\n",
    "        self.confusion_matrix_val = skm.confusion_matrix(self.y_val, class_predictions)\n",
    "        self.success_rate_val = calculate_success_rate(self.confusion_matrix_val)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the validation set\")\n",
    "            print('Average F1 score:', self.f1_mean_val)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_val)\n",
    "            print('\\nSuccess rate:', self.success_rate_val)\n",
    "\n",
    "    def save_model(self, N_model = 1):\n",
    "\n",
    "        self.model.save(f\"saved_models/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "\n",
    "    def load_model(self, N_model = 1):\n",
    "        self.model = tf.keras.models.load_model(f\"saved_models/{self.configuration['config_name']}/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "        \n",
    "\n",
    "    def plot_training_evolution(self):\n",
    "    # Plot the loss function and accuracy evolution\n",
    "\n",
    "        loss_evolution = self.learning[-1].history[\"loss\"]\n",
    "        val_loss_evolution = self.learning[-1].history[\"val_loss\"]\n",
    "        acc_evolution = self.learning[-1].history['categorical_accuracy']\n",
    "        val_acc_evolution = self.learning[-1].history['val_categorical_accuracy']\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(loss_evolution,label = \"Train set\")\n",
    "        plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss function value\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss function evolution\")\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(acc_evolution)\n",
    "        plt.plot(acc_evolution,label = \"Train set\")\n",
    "        plt.plot(val_acc_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Categorical accuracy evolution\")\n",
    "\n",
    "        print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n",
    "        print(\"Training accuracy:\", acc_evolution[-1], \", Validation accuracy:\", val_acc_evolution[-1])\n",
    "\n",
    "    def plot_cf_matrix(self):\n",
    "        # Plot the confusion matrix\n",
    "\n",
    "        plt.figure(figsize= (12,10))\n",
    "        heatmap = plt.imshow(self.confusion_matrix_test[:13,:], cmap='Blues')\n",
    "        plt.xticks(np.arange(13), star_class_labels)\n",
    "        plt.yticks(np.arange(13), star_class_labels)\n",
    "        plt.colorbar(heatmap)\n",
    "        plt.xlabel(\"Estimated spectral type\")\n",
    "        plt.ylabel(\"True spectral type\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        # Plot the metrics\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.bar(np.arange(13), height = self.f1_test[:13], tick_label = star_class_labels ,label = \"F1 score\")\n",
    "        plt.axhline(self.f1_mean_test, color='red', linestyle='--', label = 'F1 score average')\n",
    "        plt.axhline(self.success_rate_test, color='purple', label = 'Success rate')\n",
    "        plt.xlabel(\"Spectral class\")\n",
    "        plt.ylabel(\"Metric\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Number of epochs: 66 , Final training loss: 0.8153238892555237 , Final validation loss: 0.84336256980896\n",
      "Final accuracy: 0.6318125128746033 Final validation accuracy: 0.6244000196456909\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Prediction results for the validation set\n",
      "Average F1 score: 0.6321016442215686\n",
      "\n",
      "Confusion matrix:\n",
      "[[1089  289  112   15    5    0    0    0    0    0    0    0    0]\n",
      " [ 781  522  198   24    3    0    0    0    0    0    0    0    0]\n",
      " [  28   66  605  659  126    9    1    0    0    0    0    0    0]\n",
      " [   3   24  227  856  396   30    2    0    0    0    0    0    0]\n",
      " [   0    2   14  188 1070  297   16    0    3    0    0    0    0]\n",
      " [   0    0    1    4  154 1030  278   16   18    1    0    0    0]\n",
      " [   0    0    1    3   16  425  887  143   97    6    2    0    0]\n",
      " [   0    0    0    0    2   33  271  388  685  186    3    0    0]\n",
      " [   0    0    0    0    0    8   75  202  807  411   13    0    0]\n",
      " [   0    0    0    0    0    0   19   36  415 1050   44    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0   42 1475   28    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0   42 1475    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 1548]]\n",
      "\n",
      "Success rate: 0.95215\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Prediction results for the test set\n",
      "Average F1 score: 0.6120941050403714\n",
      "\n",
      "Confusion matrix:\n",
      "[[1070  271  131   18    3    1    0    0    0    0    0    0    0]\n",
      " [ 771  460  243   49    9    5    0    0    0    0    0    0    0]\n",
      " [  30   74  591  675  136   17    3    0    1    0    0    0    0]\n",
      " [  13   20  231  799  421   44    2    1    2    0    0    0    0]\n",
      " [   0    2   18  174  986  286   30    4    7    2    0    0    0]\n",
      " [   0    0    5    9  159 1100  269   31   21    4    1    0    0]\n",
      " [   0    0    1    1   33  379  857  133   78   18    3    0    0]\n",
      " [   0    0    0    0    2   36  270  365  678  238   23    0    0]\n",
      " [   0    0    0    0    3    9  134  203  743  445   17    0    0]\n",
      " [   0    0    0    0    0    2   28   35  394  983   76    0    0]\n",
      " [   0    0    0    0    0    0    0    1    2   41 1417   42    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0   52 1521    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    3 1535]]\n",
      "\n",
      "Success rate: 0.93585\n"
     ]
    }
   ],
   "source": [
    "architecture = tf.keras.Sequential([\n",
    "    layers.Dense(26, input_shape=[24], activation='sigmoid', kernel_initializer= initializer),\n",
    "    layers.Dense(26, activation='sigmoid', kernel_initializer= initializer),\n",
    "    layers.Dense(13, activation = 'softmax', kernel_initializer= initializer)\n",
    "])\n",
    "\n",
    "model = softmax_model('PCA_dataset2B24', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(training_epochs= 100, learning_rate= 0.05, patience_epochs= 10)\n",
    "model.predict_val()\n",
    "model.predict_test()\n",
    "model.plot_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = tf.keras.Sequential([\n",
    "    layers.Dense(100, input_shape=[30], activation='relu', kernel_initializer= initializer),\n",
    "    layers.Dense(100, activation='relu', kernel_initializer= initializer),\n",
    "    layers.Dense(100, activation='relu', kernel_initializer= initializer),\n",
    "    layers.Dense(13, activation = 'softmax', kernel_initializer= initializer)\n",
    "])\n",
    "model2 = softmax_model('PCA_dataset2B30', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.train_model(training_epochs= 100, learning_rate= 0.001, patience_epochs= 10)\n",
    "model2.predict_val()\n",
    "model2.predict_test()\n",
    "model2.plot_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = tf.keras.Sequential([\n",
    "    layers.Dense(50, input_shape=[30], activation = 'relu',kernel_regularizer = tf.keras.regularizers.l2(1e-3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(50, activation = 'relu',kernel_regularizer = tf.keras.regularizers.l2(1e-3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(50, activation = 'relu',kernel_regularizer = tf.keras.regularizers.l2(1e-3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(13, activation = 'softmax', kernel_initializer= initializer)\n",
    "])\n",
    "model3 = softmax_model('PCA_dataset2B30', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.train_model(training_epochs= 100, learning_rate= 0.001, patience_epochs= 10)\n",
    "model3.predict_val()\n",
    "model3.predict_test()\n",
    "model3.plot_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model\n",
    "\n",
    "model_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/single_model/my_model.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "\n",
    "os.makedirs(\"single_model\", exist_ok=True)\n",
    "model.save(f\"single_model/my_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function and accuracy evolution\n",
    "\n",
    "loss_evolution = learning.history[\"loss\"]\n",
    "val_loss_evolution = learning.history[\"val_loss\"]\n",
    "acc_evolution = learning.history['categorical_accuracy']\n",
    "val_acc_evolution = learning.history['val_categorical_accuracy']\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_evolution,label = \"Train set\")\n",
    "plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss function value\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss function evolution\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(acc_evolution)\n",
    "plt.plot(acc_evolution,label = \"Train set\")\n",
    "plt.plot(val_acc_evolution,label = \"Validation set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Categorical accuracy evolution\")\n",
    "\n",
    "print(\"Total training time:\", training_time, \"seconds\")\n",
    "print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
