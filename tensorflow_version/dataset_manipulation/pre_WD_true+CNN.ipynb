{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script that receives an unclassified PSF dataset and adds the remaining stars in the FOV with SEDs assigned by a CNN classifier\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets, there is the assumption that the datasets are coherent\n",
    "dataset_path = '/Users/as274094/Documents/psf_dataset4/'\n",
    "dataset_name_1 = 'train_Euclid_500_stars_id_004GT_350_bins.npy'\n",
    "dataset_name_2 = 'train_Euclid_2000_stars_id_004GT_350_bins.npy'\n",
    "dataset_1 = np.load(dataset_path + dataset_name_1, allow_pickle=True)[()] # Dataset with true SEDs\n",
    "dataset_2 = np.load(dataset_path + dataset_name_2, allow_pickle=True)[()] # The dataset containing the whole FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_remaining_stars = dataset_2['noisy_stars'].shape[0]-dataset_1['noisy_stars'].shape[0]\n",
    "\n",
    "true_SEDs = np.array(dataset_2['SED_ids'][-n_remaining_stars:])\n",
    "x_to_convert = np.expand_dims(dataset_2['noisy_stars'][-n_remaining_stars:], axis = 3)\n",
    "true_SEDs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model_path = '/Users/as274094/GitHub/Refractored_star_classifier/tensorflow_version/best_models/CNN_model/'\n",
    "classifier = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 12ms/step\n",
      "Average F1 score: 0.6830978949430104\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 69  37   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 45  68  13   0   1   0   0   0   0   0   0   0   0]\n",
      " [  1   7  73  26   2   0   0   0   0   0   0   0   0]\n",
      " [  0   2  35  54  19   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1  11  88  10   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  22  71  29   1   0   0   0   0   0]\n",
      " [  0   0   0   0   4  20  85  12   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0  20  67  17   8   0   0   0]\n",
      " [  0   0   0   0   0   0   2  51  30  28   0   0   0]\n",
      " [  0   0   0   0   0   0   0   9  21  76   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2 109   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 127   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 121]]\n",
      "\n",
      "Success rate: 0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and calculate metrics\n",
    "\n",
    "y_test_pred = classifier.predict(x_to_convert, verbose = 1)\n",
    "class_predictions = np.argmax(y_test_pred, axis = 1)\n",
    "\n",
    "f1_mean = np.mean(skm.f1_score(true_SEDs, class_predictions, average = None)[:13])\n",
    "print('Average F1 score:', f1_mean)\n",
    "\n",
    "confusion_matrix = skm.confusion_matrix(true_SEDs, class_predictions)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "success_rate = calculate_success_rate(confusion_matrix)\n",
    "print('\\nSuccess rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 350, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign SEDs\n",
    "concatenated_SEDs = np.load('concatenated_SEDs.npy', allow_pickle=True)[()]\n",
    "\n",
    "SED_list = []\n",
    "for spectral_class in class_predictions:\n",
    "    concat_SED = concatenated_SEDs[spectral_class]\n",
    "    SED_list.append(concat_SED)\n",
    "SED_array = np.array(SED_list, dtype=object)\n",
    "SED_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dataset\n",
    "\n",
    "dataset_2['SED_ids'] = np.append(dataset_1['SED_ids'],class_predictions)\n",
    "dataset_2['SEDs'] = np.concatenate((dataset_1['SEDs'],SED_array))\n",
    "dataset_2['F1'] = f1_mean\n",
    "dataset_2['success_rate'] = success_rate\n",
    "\n",
    "np.save(\n",
    "        dataset_path + 'expanded_CNN_' + dataset_name_1,\n",
    "        dataset_2,\n",
    "        allow_pickle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6830978949430104 0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "\n",
    "expanded_dataset = np.load('/Users/as274094/Documents/psf_dataset4/expanded_CNN_train_Euclid_500_stars_id_004GT_350_bins.npy', allow_pickle=True)[()]\n",
    "print(expanded_dataset['F1'],expanded_dataset['success_rate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
