{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.metrics as skm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate configurations\n",
    "\n",
    "hidden_layers = [2, 3, 4]\n",
    "hidden_nodes = [26, 5, 11, 20, 32, 40]\n",
    "activation = ['sigmoid', 'relu']\n",
    "\n",
    "configurations = []\n",
    "\n",
    "for index, combination in enumerate(itertools.product(hidden_layers, hidden_nodes, activation), 1):\n",
    "    config = {\n",
    "        'config_name': f'config{index}',\n",
    "        'hidden_layers' : combination[0],\n",
    "        'hidden_nodes': combination[1],\n",
    "        'activation': combination[2]\n",
    "    }\n",
    "    configurations.append(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '/Users/as274094/Documents/psf_dataset2/'\n",
    "# data_path = '/gpfswork/rech/prk/uzk69cg/psf_dataset2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEDlisttoC(SED_list):\n",
    "    sed_array = np.array(SED_list)\n",
    "    return sed_array*0.5 + 1.5\n",
    "\n",
    "def CtoSEDarray(c_values, variance):\n",
    "    sed_classes = ((c_values - 1.25) // 0.5).astype(int)\n",
    "    sed_classes = np.where((c_values < 1.25) | (c_values > 7.75), 20, sed_classes)\n",
    "    sed_classes = np.where((variance > 1.00), 20, sed_classes)\n",
    "    return sed_classes\n",
    "\n",
    "def calculate_success_rate(confusion_matrix):\n",
    "    diagonal = np.trace(confusion_matrix)\n",
    "    diagonal_neighbors = np.sum(np.diagonal(confusion_matrix, offset=1)) + np.sum(np.diagonal(confusion_matrix, offset=-1))\n",
    "    total_classified = np.sum(confusion_matrix)\n",
    "    \n",
    "    success_rate = (diagonal + diagonal_neighbors) / total_classified\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCompletionCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        epochs = len(self.model.history.history['loss'])\n",
    "        final_loss = self.model.history.history['loss'][-1]\n",
    "        final_val_loss = self.model.history.history['val_loss'][-1]\n",
    "\n",
    "        print(\"Training completed. Number of epochs:\", epochs, \", Final training loss:\", final_loss, \", Final validation loss:\", final_val_loss)\n",
    "\n",
    "completion_callback = TrainingCompletionCallback()\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class full_model:\n",
    "    def __init__(self, dataset_name, configuration):\n",
    "        self.dataset_name = dataset_name\n",
    "        dataset = np.load(data_path + dataset_name + \".npy\", allow_pickle=True)[()]\n",
    "        self.PCA_components = dataset['N_components']\n",
    "        self.x_train = dataset['train_stars_pca']\n",
    "        self.x_val = dataset['validation_stars_pca']\n",
    "        self.x_test = dataset['test_stars_pca']\n",
    "        self.y_train = dataset['train_C']\n",
    "        self.y_val = dataset['validation_C']\n",
    "        self.y_test = dataset['test_C']\n",
    "        self.SED_val = dataset['validation_SEDs']\n",
    "        self.SED_test = dataset['test_SEDs']\n",
    "        self.learning = []\n",
    "        self.configuration = configuration\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(layers.Input(shape=[self.PCA_components]))\n",
    "        for n_layers in range(self.configuration['hidden_layers']):\n",
    "            self.model.add(layers.Dense(self.configuration['hidden_nodes'], activation= self.configuration['activation'], kernel_initializer= initializer))\n",
    "        self.model.add(layers.Dense(1, activation = 'linear', kernel_initializer= initializer))\n",
    "        \n",
    "    \n",
    "    def train_model(self, learning_rate, training_epochs, patience_epochs):\n",
    "\n",
    "        self.model.compile(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        )\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = patience_epochs, restore_best_weights=True)\n",
    "\n",
    "        learn = self.model.fit(self.x_train, self.y_train, epochs= training_epochs, verbose = 0,\n",
    "                                        callbacks = [completion_callback,early_stopping], validation_data=(self.x_val,self.y_val), shuffle=True) \n",
    "\n",
    "        self.learning.append(learn)\n",
    "\n",
    "    def predict_test(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_test, verbose = 0).reshape(-1)\n",
    "        SED_pred_test = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_test = np.mean((self.y_test - C_pred)**2)\n",
    "        self.f1_test = skm.f1_score(self.SED_test, SED_pred_test, average = None)\n",
    "        self.f1_mean_test = np.mean(self.f1_test[:13])\n",
    "        self.confusion_matrix_test = skm.confusion_matrix(self.SED_test, SED_pred_test)\n",
    "        self.success_rate_test = calculate_success_rate(self.confusion_matrix_test)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the test set\")\n",
    "            print('MSE:', self.mse_test)\n",
    "            print('\\nF1 score for each class:', self.f1_test)\n",
    "            print('Average F1 score:', self.f1_mean_test)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_test)\n",
    "            print('\\nSuccess rate:', self.success_rate_test)\n",
    "\n",
    "\n",
    "    def predict_val(self, verbose = True):\n",
    "        C_pred = self.model.predict(self.x_val, verbose = 0).reshape(-1)\n",
    "        SED_pred_val = CtoSEDarray(C_pred,np.zeros_like(C_pred))\n",
    "\n",
    "        self.mse_val = np.mean((self.y_val - C_pred)**2) \n",
    "        self.f1_val = skm.f1_score(self.SED_val, SED_pred_val, average = None)\n",
    "        self.f1_mean_val = np.mean(self.f1_val[:13])\n",
    "        self.confusion_matrix_val = skm.confusion_matrix(self.SED_val, SED_pred_val)\n",
    "        self.success_rate_val = calculate_success_rate(self.confusion_matrix_val)\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Prediction results for the validation set\")\n",
    "            print('MSE:', self.mse_val)\n",
    "            print('\\nF1 score for each class:', self.f1_val)\n",
    "            print('Average F1 score:', self.f1_mean_val)\n",
    "            print(\"\\nConfusion matrix:\")\n",
    "            print(self.confusion_matrix_val)\n",
    "            print('\\nSuccess rate:', self.success_rate_val)\n",
    "\n",
    "    def save_model(self, N_model):\n",
    "\n",
    "        self.model.save(f\"saved_models/{self.configuration['config_name']}/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "\n",
    "    def load_model(self, N_model):\n",
    "        self.model = tf.keras.models.load_model(f\"saved_models/{self.configuration['config_name']}/{self.dataset_name}/my_model_{N_model}.h5\")\n",
    "        \n",
    "\n",
    "    def plot_loss(self):\n",
    "    # Plot the loss function evolution\n",
    "\n",
    "        loss_evolution = self.learning[-1].history[\"loss\"]\n",
    "        val_loss_evolution = self.learning[-1].history[\"val_loss\"]\n",
    "\n",
    "        plt.figure(figsize = (9,5))\n",
    "        plt.plot(loss_evolution,label = \"Train set\")\n",
    "        plt.plot(val_loss_evolution,label = \"Validation set\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss function value\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss function evolution\")\n",
    "        print(\"Training loss:\", loss_evolution[-1], \", Validation loss:\", val_loss_evolution[-1])\n",
    "\n",
    "    def plot_cf_matrix(self):\n",
    "        # Plot the confusion matrix\n",
    "\n",
    "        star_class_labels = ['O5','B0','B5','A0','A5','F0','F5','G0','G5','K0','K5','M0','M5']\n",
    "\n",
    "        plt.figure(figsize= (12,10))\n",
    "        heatmap = plt.imshow(self.confusion_matrix_test[:13,:], cmap='Blues')\n",
    "        plt.xticks(np.arange(14), star_class_labels + ['???'])\n",
    "        plt.yticks(np.arange(13), star_class_labels)\n",
    "        plt.colorbar(heatmap)\n",
    "        plt.xlabel(\"Estimated spectral type\")\n",
    "        plt.ylabel(\"True spectral type\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_array(N_components, N_model_dataset, configuration):\n",
    "    model_array = np.empty((len(N_components),N_model_dataset), dtype=object)\n",
    "\n",
    "    total_start_time = time.time() # Measure training time\n",
    "    for i in range(model_array.shape[0]):\n",
    "        print('Start of the training of PCA_dataset2B' + str(N_components[i]))\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = full_model('PCA_dataset2B' + str(N_components[i]), configuration)\n",
    "            model.create_model()\n",
    "\n",
    "            single_start_time = time.time()\n",
    "            model.train_model(training_epochs= 70, learning_rate= 0.1, patience_epochs= 10)\n",
    "            model.train_model(training_epochs= 100, learning_rate= 0.01, patience_epochs= 12)\n",
    "            single_end_time = time.time()\n",
    "            single_training_time = single_end_time - single_start_time\n",
    "            print(\"Model training time:\", single_training_time, \"seconds\")\n",
    "\n",
    "            model.predict_val(verbose=0)\n",
    "            model.predict_test(verbose=0)\n",
    "            model_array[i][j]= model\n",
    "        print('End of the training of PCA_dataset2B' + str(N_components[i]))\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    total_training_time = total_end_time - total_start_time\n",
    "    print(\"Total training time:\", total_training_time, \"seconds\")\n",
    "\n",
    "    return model_array\n",
    "\n",
    "def predict_array(model_array):\n",
    "    for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model_array[i][j].predict_test(verbose=False)\n",
    "\n",
    "def save_model_array(model_array):\n",
    "    for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = model_array[i][j]\n",
    "            model.save_model(j)\n",
    "\n",
    "def load_model_array(N_components, N_model_dataset, configuration):\n",
    "    model_array = np.empty((len(N_components), N_model_dataset), dtype=object)\n",
    "\n",
    "    for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = full_model('PCA_dataset2B' + str(N_components[i]), configuration)\n",
    "            model.load_model(j)\n",
    "            model_array[i][j] = model\n",
    "\n",
    "    return model_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_metric(model_array, metric):\n",
    "    metric_array = np.zeros_like(model_array) \n",
    "\n",
    "    for i in range(model_array.shape[0]):\n",
    "        for j in range(model_array.shape[1]):\n",
    "            model = model_array[i][j]\n",
    "            metric_array[i][j] = getattr(model, metric)\n",
    "    return metric_array\n",
    "\n",
    "def obtain_graph_values(model_array, metric):\n",
    "    metric_array = obtain_metric(model_array, metric)\n",
    "\n",
    "    mean_values = np.mean(metric_array, axis=1).astype(float)\n",
    "    min_values = np.min(metric_array, axis=1).astype(float)\n",
    "    max_values = np.max(metric_array, axis=1).astype(float)\n",
    "    return mean_values, min_values, max_values\n",
    "\n",
    "def obtain_best_models(model_array):\n",
    "    best_models = np.empty((model_array.shape[0],1), dtype = object)\n",
    "\n",
    "    F1_array = obtain_metric(model_array, 'f1_mean_test')\n",
    "    indexes = np.argmax(F1_array, axis=1)\n",
    "    for N in range(model_array.shape[0]):\n",
    "        model = model_array[N][indexes[N]]\n",
    "        best_models[N] = model\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model arrays\n",
    "\n",
    "N_components = [21, 24, 27, 30, 33]\n",
    "array_list= []\n",
    "\n",
    "for configuration in configurations[:3]:\n",
    "    print(configuration)\n",
    "    model_array = load_model_array(N_components, 10, configuration)\n",
    "    predict_array(model_array)\n",
    "    array_list.append(model_array)\n",
    "\n",
    "for configuration in configurations[5:]:\n",
    "    print(configuration)\n",
    "    model_array = load_model_array(N_components, 4, configuration)\n",
    "    predict_array(model_array)\n",
    "    array_list.append(model_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the metrics of different configuration arrays with their error shape\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "np.random.seed(3)\n",
    "# Plotting a trace for each model\n",
    "for model_array in array_list:\n",
    "    config_name = model_array[0][0].configuration['config_name']\n",
    "    col = np.random.random(3,)\n",
    "    mean_valuesSt, minSt, maxSt = obtain_graph_values(model_array, 'success_rate_test')\n",
    "    mean_valuesF1t, minF1t, maxF1t = obtain_graph_values(model_array, 'f1_mean_test')\n",
    "\n",
    "    ax1.plot(N_components, mean_valuesSt, '-o', label= config_name, color= col, linewidth=2)\n",
    "    ax1.fill_between(N_components, minSt, maxSt, alpha=0.3, color=col)\n",
    "\n",
    "    ax2.plot(N_components, mean_valuesF1t, '-o', label=config_name, color=col, linewidth=2)\n",
    "    ax2.fill_between(N_components, minF1t, maxF1t, alpha=0.3, color=col)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax1.set_ylabel(\"Success Rate\", fontsize=18)\n",
    "ax1.set_xticks(N_components)\n",
    "ax1.set_yticks((np.arange(11)*0.1))\n",
    "ax1.tick_params(axis='x', labelsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=15)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax2.set_ylabel(\"F1 Score\", fontsize=18)\n",
    "ax2.set_xticks(N_components)\n",
    "ax2.set_yticks(np.arange(11)*0.1)\n",
    "ax2.tick_params(axis='x', labelsize=15)\n",
    "ax2.tick_params(axis='y', labelsize=15)\n",
    "ax2.grid(True)\n",
    "ax2.legend(loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.0), fontsize=12)\n",
    "\n",
    "fig.suptitle('Performance of the classifier in function of the number of PCA components', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_array_list = []\n",
    "for array in array_list:\n",
    "    best_array = obtain_best_models(array)\n",
    "    best_array_list.append(best_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the metrics of the best models from different configurations\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "np.random.seed(3)\n",
    "# Plotting a trace for each model\n",
    "for model_array in best_array_list:\n",
    "    config_name = model_array[0][0].configuration['config_name']\n",
    "    col = np.random.random(3,)\n",
    "    mean_valuesSt, minSt, maxSt = obtain_graph_values(model_array, 'success_rate_test')\n",
    "    mean_valuesF1t, minF1t, maxF1t = obtain_graph_values(model_array, 'f1_mean_test')\n",
    "\n",
    "    ax1.plot(N_components, mean_valuesSt, '-o', label= config_name, color= col, linewidth=2)\n",
    "    ax2.plot(N_components, mean_valuesF1t, '-o', label=config_name, color=col, linewidth=2)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax1.set_ylabel(\"Success Rate\", fontsize=18)\n",
    "ax1.set_xticks(N_components)\n",
    "ax1.set_yticks((np.arange(8)*0.01+0.9))\n",
    "ax1.tick_params(axis='x', labelsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=15)\n",
    "ax1.set_ylim(0.9, 0.97)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax2.set_ylabel(\"F1 Score\", fontsize=18)\n",
    "ax2.set_xticks(N_components)\n",
    "ax2.set_yticks((np.arange(8)*0.01+0.6))\n",
    "ax2.tick_params(axis='x', labelsize=15)\n",
    "ax2.tick_params(axis='y', labelsize=15)\n",
    "ax2.set_ylim(0.6, 0.68)\n",
    "ax2.grid(True)\n",
    "ax2.legend(loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.0), fontsize=12)\n",
    "\n",
    "fig.suptitle('Performance of the classifier in function of the number of PCA components', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_2_layers = best_array_list[:10]\n",
    "best_3_layers = best_array_list[10:22]\n",
    "best_4_layers = best_array_list[22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the metrics of the best models from different configurations\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 3, ncols= 2, figsize=(20, 15))\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "for i, best_list in enumerate([best_2_layers,best_3_layers,best_4_layers]):\n",
    "    # Plotting a trace for each model\n",
    "    for model_array in best_list:\n",
    "        config_name = model_array[0][0].configuration['config_name']\n",
    "        col = np.random.random(3,)\n",
    "        mean_valuesSt, minSt, maxSt = obtain_graph_values(model_array, 'success_rate_test')\n",
    "        mean_valuesF1t, minF1t, maxF1t = obtain_graph_values(model_array, 'f1_mean_test')\n",
    "\n",
    "        axes[i,0].plot(N_components, mean_valuesSt, '-o', label= config_name, color= col, linewidth=2)\n",
    "        axes[i,1].plot(N_components, mean_valuesF1t, '-o', label=config_name, color=col, linewidth=2)\n",
    "\n",
    "\n",
    "    axes[i,0].set_xlabel(\"PCA components\", fontsize=18)\n",
    "    axes[i,0].set_ylabel(\"Success Rate\", fontsize=18)\n",
    "    axes[i,0].set_xticks(N_components)\n",
    "    axes[i,0].set_yticks(np.arange(11)*0.01+0.9)\n",
    "    axes[i,0].tick_params(axis='x', labelsize=15)\n",
    "    axes[i,0].tick_params(axis='y', labelsize=15)\n",
    "    axes[i,0].set_ylim(0.9, 0.97)\n",
    "    axes[i,0].grid(True)\n",
    "\n",
    "    axes[i,1].set_xlabel(\"PCA components\", fontsize=18)\n",
    "    axes[i,1].set_ylabel(\"F1 Score\", fontsize=18)\n",
    "    axes[i,1].set_xticks(N_components)\n",
    "    axes[i,1].set_yticks(np.arange(11)*0.01+0.6)\n",
    "    axes[i,1].tick_params(axis='x', labelsize=15)\n",
    "    axes[i,1].tick_params(axis='y', labelsize=15)\n",
    "    axes[i,1].set_ylim(0.6, 0.68)\n",
    "    axes[i,1].grid(True)\n",
    "    axes[i,1].legend(loc='lower center', ncol=4, bbox_to_anchor=(0.5, 1.0), fontsize=12)\n",
    "\n",
    "fig.suptitle('Performance of the classifier in function of the number of PCA components', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = [array_list[0],array_list[8],array_list[18]]\n",
    "\n",
    "for model_array in top_models:\n",
    "    print(model_array[0][0].configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the metrics of different configuration arrays with their error shape\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "np.random.seed(3)\n",
    "# Plotting a trace for each model\n",
    "for model_array in top_models:\n",
    "    config_name = model_array[0][0].configuration['config_name']\n",
    "    col = np.random.random(3,)\n",
    "    mean_valuesSt, minSt, maxSt = obtain_graph_values(model_array, 'success_rate_test')\n",
    "    mean_valuesF1t, minF1t, maxF1t = obtain_graph_values(model_array, 'f1_mean_test')\n",
    "\n",
    "    ax1.plot(N_components, mean_valuesSt, '-o', label= config_name, color= col, linewidth=2)\n",
    "    ax1.fill_between(N_components, minSt, maxSt, alpha=0.3, color=col)\n",
    "\n",
    "    ax2.plot(N_components, mean_valuesF1t, '-o', label=config_name, color=col, linewidth=2)\n",
    "    ax2.fill_between(N_components, minF1t, maxF1t, alpha=0.3, color=col)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax1.set_ylabel(\"Success Rate\", fontsize=18)\n",
    "ax1.set_xticks(N_components)\n",
    "ax1.set_yticks(np.arange(11)*0.1)\n",
    "ax1.tick_params(axis='x', labelsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=15)\n",
    "ax1.set_ylim(0.6, 1.0)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.set_xlabel(\"PCA components\", fontsize=18)\n",
    "ax2.set_ylabel(\"F1 Score\", fontsize=18)\n",
    "ax2.set_xticks(N_components)\n",
    "ax2.set_yticks(np.arange(11)*0.1)\n",
    "ax2.tick_params(axis='x', labelsize=15)\n",
    "ax2.tick_params(axis='y', labelsize=15)\n",
    "ax2.set_ylim(0.3, 0.7)\n",
    "ax2.grid(True)\n",
    "ax2.legend(loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.0), fontsize=12)\n",
    "\n",
    "fig.suptitle('Performance of the classifier in function of the number of PCA components', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
